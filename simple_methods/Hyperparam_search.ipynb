{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter search\n",
    "\n",
    "Very good performance on binary classifiers, but I wonder if I can improve the performance of the multiclass classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_type = ''\n",
    "classifier_type = 'SVM' # can be LR (logistic regression) or SVM (support vector machine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting values and diagnoses from: \n",
      "/Tank/methylation-patterns-code/methylation-patterns-izzy/data_preprocessing/dataset/pandas/m_values/TCGA-all.csv\n",
      "/Tank/methylation-patterns-code/methylation-patterns-izzy/data_preprocessing/dataset/pandas/diagnoses/TCGA-all.csv\n",
      "m_value and diagnoses shapes:\n",
      "(276016, 6224)\n",
      "(6224,)\n",
      "m values train, m values test, diagnoses train, diagnoses test shapes:\n",
      "(4668, 276016) (1556, 276016) (4668,) (1556,)\n"
     ]
    }
   ],
   "source": [
    "# adding this path so we can import get_train_and_test\n",
    "import sys\n",
    "path = '../' # needs to be in top folder (where get_train_and_test.py is)\n",
    "sys.path.append(path)\n",
    "from get_train_and_test import get_train_and_test\n",
    "root_path = path\n",
    "\n",
    "seed = 42 # using a seed for splitting up the train and test data \n",
    "# for some reason this didn't work for LR, so the results don't use a seed.\n",
    "m_values_train, m_values_test, diagnoses_train, diagnoses_test = get_train_and_test(cancer_type, use_small=False, root_path = root_path, model_path = root_path + '/simple_methods/', model_type = classifier_type + '_' + cancer_type, seed = seed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-1.21669116, -1.51058577,  3.340167  , ...,  0.15871411,\n",
       "         -4.94125638,  3.65870998],\n",
       "        [-2.17623572,  0.7018979 ,  3.45276462, ...,  0.08917521,\n",
       "         -0.04220124,  3.86710338],\n",
       "        [-0.11018184, -2.92325689,  3.35058589, ..., -3.27780004,\n",
       "          0.01476019,  4.03479652],\n",
       "        ...,\n",
       "        [-1.42362442, -2.00625456,  2.15450508, ..., -3.82074194,\n",
       "         -0.18886663,  3.27053655],\n",
       "        [-0.61854086, -0.69444665,  3.05009639, ..., -4.44277087,\n",
       "         -0.25476051,  4.11387971],\n",
       "        [-3.4226674 , -2.64021861,  3.20787357, ...,  0.0439369 ,\n",
       "         -0.12555141,  0.9169289 ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_values_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n",
      "[CV] tol=0.001, probability=True, kernel=rbf, gamma=auto .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  tol=0.001, probability=True, kernel=rbf, gamma=auto, score=0.953, total=291.4min\n",
      "[CV] tol=0.001, probability=True, kernel=rbf, gamma=auto .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 291.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  tol=0.001, probability=True, kernel=rbf, gamma=auto, score=0.950, total=284.6min\n",
      "[CV] tol=0.001, probability=True, kernel=rbf, gamma=auto .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed: 575.9min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  tol=0.001, probability=True, kernel=rbf, gamma=auto, score=0.950, total=287.8min\n",
      "[CV] tol=0.001, probability=True, kernel=rbf, gamma=auto .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed: 863.8min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  tol=0.001, probability=True, kernel=rbf, gamma=auto, score=0.960, total=286.5min\n",
      "[CV] tol=0.001, probability=True, kernel=rbf, gamma=auto .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed: 1150.3min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  tol=0.001, probability=True, kernel=rbf, gamma=auto, score=0.952, total=285.4min\n",
      "[CV] tol=0.0001, probability=True, kernel=rbf, gamma=auto ............\n",
      "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=auto, score=0.953, total=295.2min\n",
      "[CV] tol=0.0001, probability=True, kernel=rbf, gamma=auto ............\n",
      "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=auto, score=0.950, total=287.1min\n",
      "[CV] tol=0.0001, probability=True, kernel=rbf, gamma=auto ............\n",
      "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=auto, score=0.950, total=291.2min\n",
      "[CV] tol=0.0001, probability=True, kernel=rbf, gamma=auto ............\n",
      "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=auto, score=0.960, total=289.2min\n",
      "[CV] tol=0.0001, probability=True, kernel=rbf, gamma=auto ............\n",
      "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=auto, score=0.952, total=286.9min\n",
      "[CV] tol=0.0001, probability=True, kernel=rbf, gamma=scale ...........\n",
      "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=scale, score=0.928, total=191.1min\n",
      "[CV] tol=0.0001, probability=True, kernel=rbf, gamma=scale ...........\n",
      "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=scale, score=0.929, total=190.4min\n",
      "[CV] tol=0.0001, probability=True, kernel=rbf, gamma=scale ...........\n",
      "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=scale, score=0.929, total=188.8min\n",
      "[CV] tol=0.0001, probability=True, kernel=rbf, gamma=scale ...........\n",
      "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=scale, score=0.943, total=190.7min\n",
      "[CV] tol=0.0001, probability=True, kernel=rbf, gamma=scale ...........\n",
      "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=scale, score=0.921, total=188.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed: 3835.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=SVC(C=1.0, cache_size=200, class_weight=None,\n",
       "                                 coef0=0.0, decision_function_shape='ovr',\n",
       "                                 degree=3, gamma='auto_deprecated',\n",
       "                                 kernel='rbf', max_iter=-1, probability=False,\n",
       "                                 random_state=None, shrinking=True, tol=0.001,\n",
       "                                 verbose=False),\n",
       "                   iid='warn', n_iter=3, n_jobs=None,\n",
       "                   param_distributions={'gamma': ['auto', 'scale'],\n",
       "                                        'kernel': ['rbf'],\n",
       "                                        'probability': [True],\n",
       "                                        'tol': [0.001, 0.0001]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='f1_micro', verbose=5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'SVM'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# random search\n",
    "if classifier_type == 'LR':\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    model = LogisticRegression()\n",
    "    \n",
    "    \n",
    "    to_try = {'penalty': ['l2'],\n",
    "             'solver': ['saga'], # did try: 'newton-cg', 'sag', 'saga', 'lbfgs'],\n",
    "             'max_iter': randint(100, 500)}\n",
    "\n",
    "elif classifier_type == 'SVM':\n",
    "    from sklearn.svm import SVC\n",
    "    model = SVC()\n",
    "\n",
    "#     to_try = {'kernel': ['rbf', 'sigmoid'],\n",
    "#              'tol': [1e-3, 1e-4, 1e-5],\n",
    "#              'gamma': ['auto', 'scale'],\n",
    "#              'probability': [True]}\n",
    "\n",
    "to_try = {'kernel': ['rbf'], # sigmoid resulted in very low acc I think\n",
    "         'tol': [1e-3, 1e-4], # 1e-5 takes too long\n",
    "         'gamma': ['auto', 'scale'],\n",
    "         'probability': [True]}\n",
    "    \n",
    "    \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(model, to_try, n_iter=3, scoring='f1_micro', cv=5, verbose=5)\n",
    "random_search.fit(m_values_train, diagnoses_train)\n",
    "classifier_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_search_results = random_search.cv_results_\n",
    "random_search_best_estimator = random_search.best_estimator_\n",
    "\n",
    "# showing parameters and scores\n",
    "scores = random_search.cv_results_['mean_test_score']\n",
    "params = random_search.cv_results_['params']\n",
    "import pandas as pd\n",
    "pd_results = pd.DataFrame(params)\n",
    "pd_results[\"score\"] = scores\n",
    "pd_results.sort_values(by=\"score\", ascending = False)\n",
    "\n",
    "print(pd_results)\n",
    "\n",
    "# saving best model\n",
    "params = random_search.best_params_\n",
    "import json\n",
    "params = json.dumps(params) # get string rep of dictionary\n",
    "import joblib # joblib is apparently more efficient than pickle functions for model saving (see https://scikit-learn.org/stable/modules/model_persistence.html)\n",
    "joblib.dump(random_search_best_estimator, 'saved_models/'+classifier_type+'_model_multiclass_best_params_'+params+'.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Output for LR:\n",
    "\n",
    "Kept getting this warning:\n",
    "/home/in268/.local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
    "  \"of iterations.\", ConvergenceWarning)\n",
    "\n",
    "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
    "[CV] max_iter=299, penalty=l2, solver=newton-cg ......................\n",
    "[CV]  max_iter=299, penalty=l2, solver=newton-cg, score=0.969, total=73.3min\n",
    "[CV] max_iter=299, penalty=l2, solver=newton-cg ......................\n",
    "[CV]  max_iter=299, penalty=l2, solver=newton-cg, score=0.985, total=98.1min\n",
    "[CV] max_iter=299, penalty=l2, solver=newton-cg ......................\n",
    "[CV]  max_iter=299, penalty=l2, solver=newton-cg, score=0.979, total=80.2min\n",
    "[CV] max_iter=299, penalty=l2, solver=newton-cg ......................\n",
    "[CV]  max_iter=299, penalty=l2, solver=newton-cg, score=0.975, total=123.4min\n",
    "[CV] max_iter=299, penalty=l2, solver=newton-cg ......................\n",
    "[CV]  max_iter=299, penalty=l2, solver=newton-cg, score=0.977, total=122.0min\n",
    "= 0.977\n",
    "\n",
    "[CV] max_iter=106, penalty=l2, solver=lbfgs ..........................\n",
    "[CV]  max_iter=106, penalty=l2, solver=lbfgs, score=0.969, total=12.5min\n",
    "[CV] max_iter=106, penalty=l2, solver=lbfgs ..........................\n",
    "[CV]  max_iter=106, penalty=l2, solver=lbfgs, score=0.983, total=11.3min\n",
    "[CV] max_iter=106, penalty=l2, solver=lbfgs ..........................\n",
    "[CV]  max_iter=106, penalty=l2, solver=lbfgs, score=0.981, total= 8.8min\n",
    "[CV] max_iter=106, penalty=l2, solver=lbfgs ..........................\n",
    "[CV]  max_iter=106, penalty=l2, solver=lbfgs, score=0.977, total= 9.7min\n",
    "[CV] max_iter=106, penalty=l2, solver=lbfgs ..........................\n",
    "[CV]  max_iter=106, penalty=l2, solver=lbfgs, score=0.980, total=11.6min\n",
    "= 0.978\n",
    "\n",
    "[CV] max_iter=304, penalty=l2, solver=lbfgs ..........................\n",
    "[CV]  max_iter=304, penalty=l2, solver=lbfgs, score=0.970, total=18.5min\n",
    "[CV] max_iter=304, penalty=l2, solver=lbfgs ..........................\n",
    "[CV]  max_iter=304, penalty=l2, solver=lbfgs, score=0.984, total=19.1min\n",
    "[CV] max_iter=304, penalty=l2, solver=lbfgs ..........................\n",
    "[CV]  max_iter=304, penalty=l2, solver=lbfgs, score=0.977, total=22.2min\n",
    "[CV] max_iter=304, penalty=l2, solver=lbfgs ..........................\n",
    "[CV]  max_iter=304, penalty=l2, solver=lbfgs, score=0.975, total=21.6min\n",
    "[CV] max_iter=304, penalty=l2, solver=lbfgs ..........................\n",
    "[CV]  max_iter=304, penalty=l2, solver=lbfgs, score=0.977, total=21.9min\n",
    "= 0.9766\n",
    "\n",
    "[CV] max_iter=126, penalty=l2, solver=sag ............................\n",
    "[CV]  max_iter=126, penalty=l2, solver=sag, score=0.965, total=163.3min\n",
    "[CV] max_iter=126, penalty=l2, solver=sag ............................\n",
    "[CV]  max_iter=126, penalty=l2, solver=sag, score=0.978, total=164.0min\n",
    "[CV] max_iter=126, penalty=l2, solver=sag ............................\n",
    "= 0.9715\n",
    "\n",
    "\n",
    "[CV] max_iter=300, penalty=l2, solver=saga ...........................\n",
    "[CV]  max_iter=300, penalty=l2, solver=saga, score=0.966, total=499.4min\n",
    "[CV] max_iter=300, penalty=l2, solver=saga ...........................\n",
    "[CV]  max_iter=300, penalty=l2, solver=saga, score=0.978, total=499.7min\n",
    "[CV] max_iter=300, penalty=l2, solver=saga ...........................\n",
    "[CV]  max_iter=300, penalty=l2, solver=saga, score=0.976, total=501.0min\n",
    "[CV] max_iter=300, penalty=l2, solver=saga ...........................\n",
    "= 0.973\n",
    "\n",
    "So turns out that the different solvers do not seem to make much of a difference. Given the speed of lbfgs, and it marginally had the highest accuracy, this is the one I will use. \n",
    "\n",
    "params = {'penalty': 'l2',\n",
    "             'solver': 'lbfgs',\n",
    "             'max_iter': 100}\n",
    "             \n",
    "             \n",
    "             \n",
    "             \n",
    "Multiclass SVM:\n",
    "\n",
    "\n",
    "to_try = {'kernel': ['rbf', 'sigmoid'],\n",
    "         'tol': [1e-3, 1e-4, 1e-5],\n",
    "         'gamma': ['auto', 'scale'],\n",
    "         'probability': [True]}\n",
    "\n",
    "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
    "\n",
    "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=auto, score=0.953, total=286.4min\n",
    "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=auto, score=0.950, total=285.1min\n",
    "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=auto, score=0.950, total=288.2min\n",
    "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=auto, score=0.960, total=288.6min\n",
    "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=auto, score=0.952, total=284.2min\n",
    "\n",
    "[CV]  tol=0.001, probability=True, kernel=rbf, gamma=scale, score=0.928, total=184.7min\n",
    "[CV]  tol=0.001, probability=True, kernel=rbf, gamma=scale, score=0.929, total=183.8min\n",
    "[CV]  tol=0.001, probability=True, kernel=rbf, gamma=scale, score=0.929, total=184.9min\n",
    "[CV]  tol=0.001, probability=True, kernel=rbf, gamma=scale, score=0.943, total=186.9min\n",
    "[CV]  tol=0.001, probability=True, kernel=rbf, gamma=scale, score=0.921, total=184.6min\n",
    "\n",
    "[CV]  tol=1e-05, probability=True, kernel=sigmoid, gamma=auto, score=0.127, total=641.3min\n",
    "[CV]  tol=1e-05, probability=True, kernel=sigmoid, gamma=auto, score=0.127, total=642.7min\n",
    "\n",
    "New to try:\n",
    "to_try = {'kernel': ['rbf'], # sigmoid resulted in very low acc I think\n",
    "         'tol': [1e-3, 1e-4], # 1e-5 takes too long\n",
    "         'gamma': ['auto', 'scale'],\n",
    "         'probability': [True]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[CV]  tol=0.001, probability=True, kernel=rbf, gamma=auto, score=0.953, total=291.4min\n",
    "[CV]  tol=0.001, probability=True, kernel=rbf, gamma=auto, score=0.950, total=284.6min\n",
    "[CV]  tol=0.001, probability=True, kernel=rbf, gamma=auto, score=0.950, total=287.8min\n",
    "[CV]  tol=0.001, probability=True, kernel=rbf, gamma=auto, score=0.960, total=286.5min\n",
    "[CV]  tol=0.001, probability=True, kernel=rbf, gamma=auto, score=0.952, total=285.4min\n",
    "\n",
    "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=auto, score=0.953, total=295.2min\n",
    "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=auto, score=0.950, total=287.1min\n",
    "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=auto, score=0.950, total=291.2min\n",
    "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=auto, score=0.960, total=289.2min\n",
    "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=auto, score=0.952, total=286.9min\n",
    "\n",
    "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=scale, score=0.928, total=191.1min\n",
    "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=scale, score=0.929, total=190.4min\n",
    "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=scale, score=0.929, total=188.8min\n",
    "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=scale, score=0.943, total=190.7min\n",
    "[CV]  tol=0.0001, probability=True, kernel=rbf, gamma=scale, score=0.921, total=188.6min\n",
    "\n",
    "From these results, my final hyperparameter choices are:\n",
    "params = {'kernel': ['rbf'],\n",
    "         'tol': [1e-3], \n",
    "         'gamma': ['auto'],\n",
    "         'probability': [True]}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
