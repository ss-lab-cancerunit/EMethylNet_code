{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each cancer type or multiclass, creates a classifier and saves the models and results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings: \n",
    "\n",
    "cancer_types = ['BLCA', 'BRCA', 'COAD', 'ESCA', 'HNSC', 'KIRC', 'KIRP', 'LIHC', 'LUAD', 'LUSC', 'PRAD', 'THCA', 'UCEC']\n",
    "# cancer_types = [''] # uncomment for a multiclass model. Warning: this model takes ages to train! (I think roughly 1 or 2 days)\n",
    "classifier_type = 'XGBoost'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params is  {'objective': 'binary:logistic', 'max_depth': 10, 'n_estimators': 450, 'learning_rate': 0.189}\n"
     ]
    }
   ],
   "source": [
    "# for binary, chosen from results of Hyperparam_search:\n",
    "params = {'objective':'binary:logistic', 'max_depth': 10, 'n_estimators':450, 'learning_rate':0.189} # dictionary of parameters for the xgboost model\n",
    "if cancer_types == ['']: # for multiclass\n",
    "    params = {\n",
    "    'subsample': 0.5, \n",
    "    'objective': 'binary:logistic', \n",
    "    'n_estimators' : 800, \n",
    "    'max_depth' : 3, \n",
    "    'learning_rate' : 0.189, \n",
    "    'colsample_bytree' : 0.5\n",
    "}\n",
    "\n",
    "print(\"params is \", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting values and diagnoses from: \n",
      "/Tank/methylation-patterns-code/methylation-patterns-izzy/data_preprocessing/dataset/pandas/m_values/TCGA-all.csv\n",
      "/Tank/methylation-patterns-code/methylation-patterns-izzy/data_preprocessing/dataset/pandas/diagnoses/TCGA-all.csv\n",
      "m_value and diagnoses shapes:\n",
      "(276016, 6224)\n",
      "(6224,)\n",
      "m values train, m values test, diagnoses train, diagnoses test shapes:\n",
      "(4668, 276016) (1556, 276016) (4668,) (1556,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_classifier(cancer_type):\n",
    "    # get the data\n",
    "    \n",
    "    # adding this path so we can import get_train_and_test\n",
    "    import sys\n",
    "    path = '../'\n",
    "    sys.path.append(path)\n",
    "    from get_train_and_test import get_train_and_test\n",
    "    root_path = path\n",
    "    \n",
    "    \n",
    "    seed = 42 # using a seed for splitting up the train and test data \n",
    "#     seed = None # if you don't use a seed you can get different xgboost feature importances\n",
    "\n",
    "    m_values_train, m_values_test, diagnoses_train, diagnoses_test = get_train_and_test(cancer_type, use_small=False, root_path = root_path, model_path = root_path + '/xgboost/', model_type = classifier_type + '_' + cancer_type, seed = seed)\n",
    "        \n",
    "    # fit the model\n",
    "    if classifier_type == 'XGBoost':\n",
    "        # XGBoost\n",
    "        import xgboost as xgb\n",
    "        from xgboost import XGBClassifier\n",
    "        bst = xgb.XGBClassifier(**params)\n",
    "        bst.fit(m_values_train, diagnoses_train)\n",
    "    else:\n",
    "        print(\"classifier type \", classifier_type, \" not known!\")\n",
    "    \n",
    "    \n",
    "    # save\n",
    "    import joblib # joblib is apparently more efficient than pickle functions for model saving (see https://scikit-learn.org/stable/modules/model_persistence.html)\n",
    "    joblib.dump(bst, 'saved_models/xgboost_model_'+cancer_type+'.pkl')\n",
    "    booster = bst.get_booster()\n",
    "    booster.dump_model('saved_models/xgboost_trees_'+cancer_type+'.txt')\n",
    "    \n",
    "    \n",
    "    # Print important features\n",
    "    it = 0\n",
    "    lines = []\n",
    "    # important features printed into console\n",
    "    for i in bst.feature_importances_: # feature_importances is how important each feature (probe) is. Most of them seem to be 0, but some are > 0\n",
    "        if i > 0:\n",
    "#             print('feature nr: %d, importance: %7.5f'%(it, i))\n",
    "            lines.append('feature nr: %d, importance: %7.5f'%(it, i))\n",
    "        it += 1\n",
    "    # saving lines:\n",
    "    import numpy as np\n",
    "\n",
    "    # finding what number we should give the file - we want to give it a number higher than all other files of this type so we don't overwrite anything\n",
    "    import os\n",
    "    files = os.listdir('feature_importances/')\n",
    "    this_type = [file for file in files if cancer_type+'_run_' in file] # find all existing files of this type\n",
    "    if this_type == []:\n",
    "        num = 0\n",
    "    else:\n",
    "        nums = [file.split('_')[2].split('.')[0] for file in this_type] # get the numbers of the files\n",
    "        ints = map(int, nums)\n",
    "        num = max(ints) + 1 # go one bigger than the max to get a unique number\n",
    "    np.savetxt('feature_importances/'+cancer_type+'_run_'+str(num)+'.csv', lines, delimiter='\\t', fmt='%s')\n",
    "\n",
    "    # NOTE: XGBoost finds different features on consecutive runs (because of the randomness) but it finds common features between runs (with higher importance I think) - when looking at features, look at these!\n",
    "    \n",
    "    # Evaluate:\n",
    "    from Evaluate import print_evaluation\n",
    "    print_evaluation(bst, m_values_test, diagnoses_test, 'xgboost_'+cancer_type)\n",
    "    \n",
    "    # create eval curves\n",
    "    import matplotlib.pyplot as plt\n",
    "    from Evaluate import plot_curve\n",
    "    import numpy as np\n",
    "    num_classes = len(np.unique(diagnoses_test, axis=0))\n",
    "    print(\"num classes is: \", num_classes)\n",
    "    confidence = bst.predict_proba(m_values_test)\n",
    "    plot_curve('roc', diagnoses_test, confidence, num_classes, 'xgboost_'+cancer_type)\n",
    "    plot_curve('precision_recall', diagnoses_test, confidence, num_classes, 'xgboost_'+cancer_type)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "import multiprocessing as mp\n",
    "pool = mp.Pool(processes=mp.cpu_count())\n",
    "results = [pool.map(create_classifier, (cancer_type for cancer_type in cancer_types))]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
